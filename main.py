{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7905657,"sourceType":"datasetVersion","datasetId":4643697}],"dockerImageVersionId":30673,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/lillynguyen0510/amazon-reviews-classification-4-models?scriptVersionId=168481382\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-23T21:58:31.455032Z","iopub.execute_input":"2024-03-23T21:58:31.456219Z","iopub.status.idle":"2024-03-23T21:58:31.466011Z","shell.execute_reply.started":"2024-03-23T21:58:31.456182Z","shell.execute_reply":"2024-03-23T21:58:31.465117Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the dataset\nimport pandas as pd\n\ndf = pd.read_csv('/kaggle/input/amazon-food-reviews-balanced-dataset/Amazon-Food-Reviews.csv')\n\ndf.head(5)","metadata":{"execution":{"iopub.status.busy":"2024-03-23T21:58:40.984957Z","iopub.execute_input":"2024-03-23T21:58:40.985751Z","iopub.status.idle":"2024-03-23T21:58:43.476821Z","shell.execute_reply.started":"2024-03-23T21:58:40.985718Z","shell.execute_reply":"2024-03-23T21:58:43.475747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Combine Summary and Text into 1 column \ndf['Total reviews'] = df['Summary'] + \". \" + df['Text']\n\n# Drop unnecessary columns\ndf = df.reindex(columns=['Total reviews', 'Score'])\n\ndf.head(5)","metadata":{"execution":{"iopub.status.busy":"2024-03-23T22:00:36.639572Z","iopub.execute_input":"2024-03-23T22:00:36.639994Z","iopub.status.idle":"2024-03-23T22:00:37.037239Z","shell.execute_reply.started":"2024-03-23T22:00:36.639965Z","shell.execute_reply":"2024-03-23T22:00:37.036155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Make sure all entries in the column are strings\ndf['Total reviews'] = df['Total reviews'].astype(str)\n\n# Remove html line break tags\ndf['Total reviews'] = df['Total reviews'].replace(to_replace=r'<br\\s*/?>*', value=' ', regex=True)","metadata":{"execution":{"iopub.status.busy":"2024-03-23T22:01:19.896345Z","iopub.execute_input":"2024-03-23T22:01:19.896759Z","iopub.status.idle":"2024-03-23T22:01:20.413739Z","shell.execute_reply.started":"2024-03-23T22:01:19.896729Z","shell.execute_reply":"2024-03-23T22:01:20.41218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Convert columns to list\nreviews = df['Total reviews'].tolist()\nscores = df['Score'].tolist()\n\n# Check the dimension\nprint(df.shape[0])\nprint(len(reviews))\nprint(len(scores))","metadata":{"execution":{"iopub.status.busy":"2024-03-23T22:02:10.11634Z","iopub.execute_input":"2024-03-23T22:02:10.116722Z","iopub.status.idle":"2024-03-23T22:02:10.13721Z","shell.execute_reply.started":"2024-03-23T22:02:10.116694Z","shell.execute_reply":"2024-03-23T22:02:10.136045Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Word tokenization\n\nfrom nltk import word_tokenize\n\nreviews_tokenized = [] # List to store valid tokenized reviews\n\nscores_final = [] # List to store corresponding final score labels\n\nprint('Tokenizing reviews...')\n\nfor i in range(len(reviews)):\n    \n    try:\n        tokens = word_tokenize(reviews[i].lower())\n        \n        if (len(tokens) > 1): # Check for reviews that are empty or consist of 1 word\n            \n            reviews_tokenized.append(tokens)\n            \n            scores_final.append(scores[i])\n    except:\n        pass\n\nprint('Done!')\n\n# Check length of data after tokenization\n\nprint(\"Total reviews:\",len(reviews_tokenized))\nprint(\"Total score labels:\",len(scores_final),\"\\n\")\n\n# Print the first element of reviews_tokenized\n\nprint(reviews_tokenized[0])","metadata":{"execution":{"iopub.status.busy":"2024-03-23T22:04:03.934542Z","iopub.execute_input":"2024-03-23T22:04:03.935634Z","iopub.status.idle":"2024-03-23T22:10:02.953229Z","shell.execute_reply.started":"2024-03-23T22:04:03.935601Z","shell.execute_reply":"2024-03-23T22:10:02.95216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from string import punctuation\nfrom nltk.corpus import stopwords\nimport re\n\n# Further word cleaning after tokenization\n\nstopwords_english = stopwords.words('english')\n\npunctuation_list = list(punctuation)\n\n# Create another copy of reviews_tokenized for further preprocessing and experiment without affecting the original one\n\nreviews_preprocessed = reviews_tokenized.copy()\n\nprint(\"Tokenising reviews...\")\n\nfor i in range(len(reviews_tokenized)):\n    \n    new_tokens = []\n    \n    for word in reviews_tokenized[i]:\n        \n        if (word not in punctuation_list) and (word not in stopwords_english): # Remove punctuation and stop words\n            \n            word = word.replace(\"-\", \"\")  # Remove hyphens from words\n            \n            word = word.replace(\".\", \"\") # Remove dots from words to normalise abbreviations\n            \n            regex_check = re.match(f'[a-z]+', word) # Select only tokens that consist of letters from a to z\n            \n            if regex_check != None:\n                \n                if regex_check.group() == word:\n                    \n                    new_tokens.append(word)\n                    \n    reviews_preprocessed[i] = new_tokens\n\nprint('Done!')\n    \n# Check if pre-processing led to any empty reviews\n\nfor i in range(len(reviews_preprocessed)):\n    \n    if len(reviews_preprocessed[i]) == 0:\n        \n        print(\"Review\",i,\"is empty!\")\n        \n# Print the first element of reviews_preprocessed\n        \nprint(reviews_preprocessed[0])","metadata":{"execution":{"iopub.status.busy":"2024-03-23T22:12:24.56044Z","iopub.execute_input":"2024-03-23T22:12:24.560845Z","iopub.status.idle":"2024-03-23T22:13:53.088441Z","shell.execute_reply.started":"2024-03-23T22:12:24.560818Z","shell.execute_reply":"2024-03-23T22:13:53.086975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import nltk\nnltk.download('wordnet')\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk import pos_tag\n\n# Word lemmatisation\n\nwnl = WordNetLemmatizer()\n\n# Define a function to change from  Penn Treebank POS tags to format required by the WordNetLemmatizer\n\ndef penn_to_wordnet(penn_pos_tag):\n    \n    tag_dictionary = {'NN':'n', 'JJ':'a','VB':'v', 'RB':'r'}\n    \n    try:\n        return tag_dictionary[penn_pos_tag[:2]]\n    \n    except:\n        return 'n'\n    \nreviews_lemmatized = [] # List to store lemmatized reviews\n\nfor review in reviews_preprocessed:\n    \n    pos_tagged_sent = pos_tag(review)\n    \n    lemmas = []\n    \n    for word, tag in pos_tagged_sent:\n        \n        lemmas.append(wnl.lemmatize(word, pos = penn_to_wordnet(tag)))\n    \n    reviews_lemmatized.append(lemmas)\n\n# Print the first element of reviews_lemmatized\n\nprint(reviews_lemmatized[0])","metadata":{"execution":{"iopub.status.busy":"2024-03-23T22:17:37.282358Z","iopub.execute_input":"2024-03-23T22:17:37.28278Z","iopub.status.idle":"2024-03-23T22:17:37.447007Z","shell.execute_reply.started":"2024-03-23T22:17:37.28275Z","shell.execute_reply":"2024-03-23T22:17:37.445522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Combine pre-processed words for further processing\n\ndataset = []\n\nfor i in range(len(reviews_lemmatized)):\n    text = \" \".join(reviews_lemmatized[i])\n    dataset.append(text)\n\nprint(dataset[0])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Split dataset into training set and test set\n\nfrom sklearn.model_selection import train_test_split\n\nsamples_train, samples_test, scores_train, scores_test = train_test_split(dataset, scores_final, test_size = 0.3, random_state = 2024)\n\n# Check length of training set and test set\n\nno_of_training_samples = len(samples_train)\nno_of_test_samples = len(samples_test)\ntotal_samples = no_of_training_samples + no_of_test_samples\n\nprint(\"Total samples:\", total_samples)\nprint(\"Training samples:\", no_of_training_samples, (no_of_training_samples/total_samples)*100,\"%\")\nprint(\"Test samples:\", no_of_test_samples, (no_of_test_samples/total_samples)*100,\"%\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define a function to compute metrics\nimport seaborn as snsb\nimport matplotlib.pyplot as plt\n\ndef get_metrics(real_score, prediction):\n    \n    # Plot the confusion matrix\n    cm = confusion_matrix(real_score, prediction)\n    \n    sns.heatmap(cm.T, square = True, annot = True, fmt = 'd', xticklabels=[1, 2, 3, 4, 5], yticklabels=[1, 2, 3, 4, 5],\n           cmap = 'Reds')\n    \n    plt.xlabel('True Label')\n    \n    plt.ylabel('Predicted Label')\n    \n    plt.show()\n    \n    print(\"Accuracy:\" , accuracy_score(real_score, prediction))\n    print(\"F1-score:\" , f1_score(real_score, prediction, average='macro')) # Get average score for all classes\n    print(\"Precision:\" , precision_score(real_score, prediction, average='macro')) # Get average score for all classes\n    print(\"Recall:\" , recall_score(real_score, prediction, average='macro')) # Get average score for all classes\n    print(\"\\nClassification performance:\\n\" , classification_report(real_score, prediction))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Naïve Bayes model","metadata":{}},{"cell_type":"code","source":"# Naive Bayes model: setting a pipeline where the input is first converted to TF-IDF vectors \n# and then a Complement Naive Bayes is used\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.naive_bayes import ComplementNB\nfrom sklearn.pipeline import make_pipeline\n\nNB_model = make_pipeline(TfidfVectorizer(), ComplementNB())\n\n# Train the model on the training data\nNB_model.fit(samples_train, scores_train)\n\n# Fit model on the testing data\nNB_prediction = NB_model.predict(samples_test)\n\nprint(\"Predicted:\",NB_prediction.tolist()[0:10]) # Print the first 10 predictions\nprint(\"Ground truth:\",scores_test[0:10]) # Print the first 10 ground truth values","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get metrics\n\nget_metrics(scores_test, NB_prediction)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# KNN model","metadata":{}},{"cell_type":"code","source":"# Compute GloVe embeddings dictionary\n\nembeddings_dict = {}\n\nwith open('glove.6B.50d.txt', 'r', encoding='utf-8') as f: #Replace with 100d, 200d or 300d\n    \n    for line in f:\n        \n        values = line.split()\n        \n        word = values[0]\n        \n        vector  = np.asarray(values[1:], dtype = float)\n        \n        embeddings_dict[word] = vector\n        \n# Check for any bad keys which don't have 50 dimensions in the Glove embeddings\n\nbad_keys = []\n\nfor key in embeddings_dict.keys():\n    \n    if embeddings_dict[key].shape[0] != 50:       \n        print(key)\n        \n        bad_keys.append(key)\n\nprint(bad_keys)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define document embedding function\n\ndef get_document_embedding(word_list, word_embeddings, k):\n    \n    document_embedding = np.zeros(k, dtype = float) # Create embedding of k zero-valued elements\n    \n    valid_words = 0\n    \n    for word in word_list:\n        \n        try:\n            document_embedding = document_embedding + word_embeddings[word]\n            \n            valid_words += 1\n        \n        except:\n            \n            pass # If word embedding is not available, then ignore the word\n        \n    if valid_words > 0:\n        \n        document_embedding = document_embedding / valid_words\n    \n    else: \n        \n        document_embedding = np.zeros(k, dtype = float) # In case valid words = 0\n    \n    return document_embedding","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Document embeddings for samples_train\n\nsamples_train_embeddings = [] # List to store document embeddings of training data\n\nfor i in range(len(samples_train)):\n    \n    train_tokens = word_tokenize(samples_train[i]) # Tokenize each review in the training dataset\n            \n    samples_train_embeddings.append(get_document_embedding(train_tokens, embeddings_dict, 50))\n    \n\n# Document embeddings for samples_test\n\nsamples_test_embeddings = []\n    \nfor i in range(len(samples_test)):\n    \n    test_tokens = word_tokenize(samples_test[i]) # Tokenize each review in the testing set\n            \n    samples_test_embeddings.append(get_document_embedding(test_tokens, embeddings_dict, 50))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import cross_val_score\n\n# Define value for k\n\nneighbor = [1,3,5,7]\n\n# Create a dictionary to store k values and their corresponding cross-validation accuracy\n\ncv_score = {}\n\n# Iterate over k\n\nfor k in neighbor:\n    \n    model = KNeighborsClassifier(n_neighbors = k)\n    \n    # Get model accuracy using Cross-validation\n    cross_val = cross_val_score(model, samples_train_embeddings, scores_train, cv = 10, scoring = 'accuracy')\n    \n    cv_score[k] = cross_val.mean() # Add the average cross-validation accuracy to the dictionary","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Plot k and classification performance\n\nimport matplotlib.pyplot as plt\n\nplt.plot(neighbor, cv_score.values())\n\nplt.xlabel('Number of Neighbors k')\n\nplt.ylabel('Cross-Validation Accuracy')\n\nplt.title('k vs. Classification Performance')\n\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Find the best k with highest accuracy\n\nbest_k = max(cv_score, key = cv_score.get)\n\n# Train the final model using the best k value\n\nKNN_model = KNeighborsClassifier(n_neighbors = best_k)\n\n# Fit the model using training data\nKNN_model.fit(samples_train_embeddings, scores_train)\n\n# Predict on the testing data\nKNN_prediction = KNN_model.predict(samples_test_embeddings)\n\nprint(\"Predicted:\",KNN_prediction.tolist()[0:10]) # Print the first 10 predictions\nprint(\"Ground truth:\",scores_test[0:10]) # Print the first 10 ground truth values","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get metrics\n\nget_metrics(scores_test, KNN_prediction)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Convolutional Neural Network (CNN)","metadata":{}},{"cell_type":"code","source":"# Turn training set and testing set into numpy array\nimport numpy as np\n\nX_train = np.array(samples_train)\nY_train = np.array(scores_train) - 1 # NumPy array indexing at 0\nX_test = np.array(samples_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import TextVectorization\n\n# The maximum number of words to be used (most frequent words in the dataset)\nmax_vocabulary = 20000\n\n# Number of words in each text. All sequences will be padded or truncated to this length.\nmax_sequence_length = 200\n\n# Create a preprocessing layer which maps text features to integer sequences\nvectorize_layer = TextVectorization(max_tokens = max_vocabulary,\n                                    output_mode = 'int', # Represent each word in the vocabulary with an integer\n                                    output_sequence_length = max_sequence_length)\n\n# Computes a vocabulary of string terms from tokens in a dataset\nvectorize_layer.adapt(X_train)\n\n# Check vocabulary length\nprint(\"Vocabulary size: \" + str(len(vectorize_layer.get_vocabulary())) + \" words\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define CNN architecture\n\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Input, Embedding, Conv1D, GlobalMaxPooling1D, Dense, Dropout\n\nembedding_dim = 20 # Size of the word embedding to be used\n\nCNN_model = Sequential(name='MyCNN')\n\nCNN_model.add(vectorize_layer)\n\n# Add Embedding layer\nCNN_model.add(Embedding(input_dim=max_vocabulary,  # Size of the vocabulary\n                    output_dim=embedding_dim,  # Size of the word embedding\n                    input_length=max_sequence_length))  # Length of input sequences\n\n# First Conv1D layer\nCNN_model.add(Conv1D(filters=32, kernel_size=2, activation='relu', padding='same'))\n\n# Add Dropout layer\nCNN_model.add(Dropout(0.2))\n\n# Second Conv1D layer\nCNN_model.add(Conv1D(filters=64, kernel_size=3, activation='relu', padding='same'))\n\n# Another Dropout layer\nCNN_model.add(Dropout(0.2))\n\n# GlobalMaxPooling1D to reduce the dimensions for the Dense layer\nCNN_model.add(GlobalMaxPooling1D())\n\n# Output layer which output probability for each class\nCNN_model.add(Dense(5, activation='softmax'))\n\nCNN_model.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define hyperparameters\n\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\n\nepochs = 20\nbatch_size = 1000\nlearning_rate = 0.01\n\nopt = Adam(learning_rate = learning_rate) # Initialise Adam optimiser with a leanring rate of 0.01\nCNN_model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy']) # Initialise model\n\n# Define early stopping that will stop after 4 epochs if there is no improvement to the accuracy\nearly_1 = EarlyStopping(monitor = 'val_accuracy', patience = 4, \n                     restore_best_weights = True, mode = 'auto')\n\n# Fit the model\nCNN_model_fit = CNN_model.fit(X_train, Y_train,\n                   epochs = epochs, batch_size = batch_size, \n                   validation_split = 0.2, # Use 20% of training data as validation data\n                   callbacks = [early_1])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predict on the testing data\n\nCNN_prediction = CNN_model.predict(X_test)\n\n# Return the indices of the maximum values along the row and plus 1 to adjust the indices as the trained labels start from 0 to 4\n\nCNN_class_prediction = np.argmax(CNN_prediction, axis = -1) + 1\n\nprint(\"Predicted:\",CNN_class_prediction.tolist()[0:10]) # Print the first 10 predictions\nprint(\"Ground truth:\",scores_test[0:10]) # Print the first 10 ground truth values","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get metrics\n\nget_metrics(scores_test, CNN_class_prediction)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Long Short-Term Memory (LSTM) model","metadata":{}},{"cell_type":"code","source":"# Turn training set and testing set into numpy array\nimport numpy as np\n\nX_train = np.array(samples_train)\nY_train = np.array(scores_train) - 1 # NumPy array indexing at 0\nX_test = np.array(samples_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.layers import TextVectorization\n\n# The maximum number of words to be used (most frequent words in the dataset)\nmax_vocabulary = 20000\n\n# Number of words in each text. All sequences will be padded or truncated to this length.\nmax_sequence_length = 200\n\n# Create a preprocessing layer which maps text features to integer sequences\nvectorize_layer = TextVectorization(max_tokens = max_vocabulary,\n                                    output_mode = 'int', # Represent each word in the vocabulary with an integer\n                                    output_sequence_length = max_sequence_length)\n\n# Computes a vocabulary of string terms from tokens in a dataset\nvectorize_layer.adapt(X_train)\n\n# Check vocabulary length\nprint(\"Vocabulary size: \" + str(len(vectorize_layer.get_vocabulary())) + \" words\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define model architecture \n\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Input, Embedding, Dense, Dropout, Bidirectional, LSTM\n\nembedding_dim = 20 # Size of the word embedding to be used\n\nLSTM_model = Sequential(name = 'MyLSTM')\n\nLSTM_model.add(Input(shape = (1,), dtype = tf.string))\n\nLSTM_model.add(vectorize_layer)\n\n# Add Embedding layer\nLSTM_model.add(Embedding(input_dim = max_vocabulary, # Size of the vocabulary\n                   output_dim = embedding_dim, # Size of the word embedding\n                    input_length = max_sequence_length)) #length of input sequences\n\n# First BiDirectional LSTM layer. Set return_sequences=True for additional LSTM layer\nLSTM_model.add(Bidirectional(LSTM(16, return_sequences = True)))\n\n# Second BiDirectional LSTM layer with Dropout\nLSTM_model.add(Bidirectional(LSTM(16, go_backwards=True, dropout=0.2)))\n\n# Output layer which output probability for each class\nLSTM_model.add(Dense(5, activation = 'softmax'))\n\nLSTM_model.summary()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define hyperparameters\n\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import EarlyStopping\n\nepochs = 20\nbatch_size = 1000\nlearning_rate = 0.01\n\nopt = Adam(learning_rate = learning_rate) # Initialise Adam optimiser with a leanring rate of 0.01\n\nLSTM_model.compile(loss='sparse_categorical_crossentropy', optimizer=opt, metrics=['accuracy']) # Initialise model\n\n# Define early stopping that will stop after 4 epochs if there is no improvement to the accuracy\nearly_2 = EarlyStopping(monitor = 'val_accuracy', patience = 4, \n                     restore_best_weights = True, mode = 'auto')\n\n# Fit the model\nLSTM_model_fit = LSTM_model.fit(X_train, Y_train,\n                   epochs = epochs, batch_size = batch_size, \n                   validation_split = 0.2, \n                   callbacks = [early_2])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predict on the testing data\nLSTM_prediction = LSTM_model.predict(X_test)\n\n# Return the indices of the maximum values along the row and plus 1 to adjust the indices as the trained labels start from 0 to 4\nLSTM_class_prediction = np.argmax(LSTM_prediction, axis=-1) + 1\n\nprint(\"Predicted:\",LSTM_class_prediction.tolist()[0:10]) # Print the first 10 predictions\nprint(\"Ground truth:\",scores_test[0:10]) # Print the first 10 ground truth values","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Get metrics\n\nget_metrics(scores_test, LSTM_class_prediction)","metadata":{},"execution_count":null,"outputs":[]}]}