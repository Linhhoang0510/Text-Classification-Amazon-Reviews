{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save 4 trained models\n",
    "import pickle\n",
    "\n",
    "pickle.dump(NB_model, open('myNB.pkl', 'wb'))\n",
    "pickle.dump(KNN_model, open('myKNN.pkl', 'wb'))\n",
    "pickle.dump(CNN_model, open('myCNN.pkl', 'wb'))\n",
    "pickle.dump(LSTM_model, open('myLSTM.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define predict_food_review function\n",
    "\n",
    "def predict_food_review(text, model):\n",
    "    \n",
    "    # Import word_cleaned function from text_clean_function.py file defined and uploaded outside this notebook \n",
    "    # so that the function will run automatically\n",
    "    from text_clean_function import word_cleaned \n",
    "    \n",
    "    # Import get_document_embedding function from document_embedding.py file defined and uploaded outside this notebook \n",
    "    # so that the function will run automatically\n",
    "    from document_embedding import get_document_embedding \n",
    "    \n",
    "    from nltk import word_tokenize\n",
    "    \n",
    "    import pickle\n",
    "    \n",
    "    import numpy as np\n",
    "    \n",
    "    # Word_cleaned function return a string after words have been tokenized, removed punctuationand stop words, and lemmatized\n",
    "    new_text = [word_cleaned(text)] \n",
    "    \n",
    "    # Load model\n",
    "    loaded_model = pickle.load(open(model, 'rb'))\n",
    "    \n",
    "    if (model == 'myCNN.pkl') or (model == 'myLSTM.pkl'):\n",
    "        \n",
    "        # If model is CNN or LSTM, turn input into numpy array\n",
    "        new_text_np = np.array(new_text)\n",
    "        \n",
    "        # Predict on the cleaned text\n",
    "        prediction = loaded_model.predict(new_text_np)\n",
    "        \n",
    "        class_prediction = np.argmax(prediction, axis=-1) + 1\n",
    "        \n",
    "        # Turn prediction into integer type\n",
    "        class_prediction = class_prediction.astype(int)\n",
    "        \n",
    "        # Print-out messages for different models\n",
    "        if model == 'myCNN.pkl':\n",
    "        \n",
    "            print('Predicted value for CNN:', class_prediction)\n",
    "        \n",
    "        else:\n",
    "            \n",
    "            print('Predicted value for LSTM:', class_prediction)\n",
    "        \n",
    "    elif (model == 'myKNN.pkl'):\n",
    "        \n",
    "        # If model is KNN, turn input into document embedding\n",
    "        new_text_document_embedding = get_document_embedding(word_tokenize(word_cleaned(text)), 50)\n",
    "        \n",
    "        # Reshape document embedding from 1 dimension to 2 dimensions required by the trained models\n",
    "        new_text_document_embedding = new_text_document_embedding.reshape(1, -1)\n",
    "        \n",
    "        prediction = loaded_model.predict(new_text_document_embedding)\n",
    "        \n",
    "        print('Predicted value for KNN:', prediction)\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        # For ComplementNB, new_text will be converted into TF-IDF vector in its pipeline\n",
    "        prediction = loaded_model.predict(new_text)\n",
    "        \n",
    "        print('Predicted value for NB:', prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check results\n",
    "predict_food_review(\"This chocolate product is horrible. Don't buy it.\", 'myNB.pkl')\n",
    "predict_food_review(\"This chocolate product is horrible. Don't buy it.\", 'myKNN.pkl')\n",
    "predict_food_review(\"This chocolate product is horrible. Don't buy it.\", 'myCNN.pkl')\n",
    "predict_food_review(\"This chocolate product is horrible. Don't buy it.\", 'myLSTM.pkl')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
